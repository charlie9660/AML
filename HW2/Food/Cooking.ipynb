{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (a) Join the What’s Cooking competition on Kaggle. Download the training and test data (in\n",
    "# .json). The competition page describes how these files are formatted.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_data = pd.read_json(\"train.json\")\n",
    "test_data = pd.read_json(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dish is 39774\n",
      "unique types of cusines is 20\n",
      "number of unique ingredients in training set is 6714\n"
     ]
    }
   ],
   "source": [
    "# (b) Tell us about the data. How many samples (dishes) are there in the training set? How many\n",
    "# categories (types of cuisine)? Use a list to keep all the unique ingredients appearing in the\n",
    "# training set. How many unique ingredients are there?\n",
    "num_dish = train_data.shape[0]\n",
    "print \"number of dish is\",num_dish\n",
    "print \"unique types of cusines is\",train_data['cuisine'].describe()['unique']\n",
    "train_ingredients = pd.DataFrame(train_data['ingredients'].tolist()).stack()\n",
    "test_ingredients = pd.DataFrame(test_data['ingredients'].tolist()).stack()\n",
    "print \"number of unique ingredients in training set is\",train_ingredients.describe()['unique']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (c) Represent each dish by a binary ingredient feature vector. Suppose there are d different ingredients\n",
    "# in total from the training set, represent each dish by a 1×d binary ingredient vector\n",
    "# x, where xi = 1 if the dish contains ingredient i and xi = 0 otherwise. For example, suppose\n",
    "# all the ingredients we have in the training set are { beef, chicken, egg, lettuce, tomato, rice }\n",
    "# and the dish is made by ingredients { chicken, lettuce, tomato, rice }, then the dish could be\n",
    "# represented by a 6×1 binary vector [0, 1, 0, 1, 1, 1] as its feature or attribute. Use n ×d feature\n",
    "# matrix to represent all the dishes in training set and test set, where n is the number of dishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######Method 1#####  >1 hour\n",
    "#train= train_data['ingredients'].str.join(sep='*').str.get_dummies(sep='*') --very slow\n",
    "#test = test_data['ingredients'].str.join(sep='*').str.get_dummies(sep='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # ######Method 2#####  ~15 min on 8GB i5 machine\n",
    "# # train_ing= pd.get_dummies(train_ingredients)\n",
    "# # test_ing= pd.get_dummies(test_ingredients)\n",
    "# # train= [train_ing.loc[i].sum(axis=0).transpose() for i in range(num_dish)]\n",
    "# # test= [test_ing.loc[i].sum(axis=0).transpose() for i in range(test_data.shape[0])]\n",
    "# train_array = pd.DataFrame(train)\n",
    "# test_array = pd.DataFrame(test)\n",
    "# common_col = list(set(train_array.columns.values).intersection(set(test_array.columns.values)))\n",
    "# train_df = train_array[common_col]\n",
    "# test_df = test_array[common_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######Method 3#####  ~2 mins\n",
    "train_ingredients_list = train_ingredients.unique().tolist()\n",
    "test_ingredients_list = test_ingredients.unique().tolist()\n",
    "common_list = list(set(train_ingredients_list).intersection(test_ingredients_list))\n",
    "train_df = [np.isin(common_list,x) for x in train_data['ingredients']]\n",
    "test_df = [np.isin(common_list,x) for x in test_data['ingredients']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charles/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian average accuracy:  0.369814620175\n",
      "Bernoulli average accuracy:  0.713983983649\n"
     ]
    }
   ],
   "source": [
    "# (d) Using Naïve Bayes Classifier to perform 3 fold cross-validation on the training set and report\n",
    "# your average classification accuracy. Try both Gaussian distribution prior assumption and\n",
    "# Bernoulli distribution prior assumption.\n",
    "# (e) For Gaussian prior and Bernoulli prior, which performs better in terms of cross-validation\n",
    "# accuracy? Why? Please give specific arguments.\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from sklearn import cross_validation\n",
    "gaussian = GaussianNB()\n",
    "bernoulli = BernoulliNB()\n",
    "train_label = train_data['cuisine']\n",
    "gaussian_scores = cross_validation.cross_val_score(gaussian,train_df,train_label,cv=3)\n",
    "bernoulli_scores = cross_validation.cross_val_score(bernoulli,train_df,train_label,cv=3)\n",
    "print \"Gaussian average accuracy: \", np.mean(gaussian_scores)\n",
    "print \"Bernoulli average accuracy: \", np.mean(bernoulli_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression average accuracy:  0.773671913969\n"
     ]
    }
   ],
   "source": [
    "# (f ) Using Logistic Regression Model to perform 3 fold cross-validation on the training set and\n",
    "# report your average classification accuracy.\n",
    "from sklearn import linear_model\n",
    "logit = linear_model.LogisticRegression()\n",
    "\n",
    "logit_scores = cross_validation.cross_val_score(logit,train_df,train_label,cv=3)\n",
    "print \"Logistic Regression average accuracy: \", np.mean(logit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (g) Train your best-performed classifier with all of the training data, and generate test labels on\n",
    "# test set. Submit your results to Kaggle and report the accuracy\n",
    "logit.fit(train_df,train_label)\n",
    "results = logit.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#score 0.78368 \n",
    "out_df = pd.DataFrame(results,columns=['cuisine'])\n",
    "out_df['id'] = test_data['id']\n",
    "out_df.to_csv(\"prediction.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
